# Configuraci√≥n de Modelos IA - Notebook Architect

## üöÄ Proveedores Soportados

### üñ•Ô∏è LM Studio (Local)
- **Endpoint por defecto**: `http://localhost:1234/v1/chat/completions`
- **Requiere API Key**: No
- **Descripci√≥n**: Ejecuta modelos locales con LM Studio
- **Modelos sugeridos**: Qwen2.5-Coder, Llama, CodeLlama
- **Instalaci√≥n**: Descargar desde [lmstudio.ai](https://lmstudio.ai)

### ü¶ô Ollama (Local)
- **Endpoint por defecto**: `http://localhost:11434/api/chat`
- **Requiere API Key**: No
- **Descripci√≥n**: Ejecuta modelos locales con Ollama
- **Modelos sugeridos**: `llama3.1`, `qwen2.5-coder`, `codellama`, `mistral`
- **Instalaci√≥n**: `curl -fsSL https://ollama.ai/install.sh | sh`

### ü§ñ OpenAI (Nube)
- **Endpoint por defecto**: `https://api.openai.com/v1/chat/completions`
- **Requiere API Key**: S√≠
- **Descripci√≥n**: API de OpenAI (GPT-4, GPT-3.5, etc.)
- **Modelos disponibles**: `gpt-4`, `gpt-4-turbo`, `gpt-3.5-turbo`, `gpt-4o`
- **Obtener API Key**: [platform.openai.com/api-keys](https://platform.openai.com/api-keys)

### üß† Anthropic Claude (Nube)
- **Endpoint por defecto**: `https://api.anthropic.com/v1/messages`
- **Requiere API Key**: S√≠
- **Descripci√≥n**: API de Anthropic (Claude 3)
- **Modelos disponibles**: `claude-3-opus-20240229`, `claude-3-sonnet-20240229`, `claude-3-haiku-20240307`
- **Obtener API Key**: [console.anthropic.com](https://console.anthropic.com)

### ‚öôÔ∏è Endpoint Personalizado
- **Endpoint**: Configuraci√≥n manual
- **Requiere API Key**: Configurable
- **Descripci√≥n**: Para otros servicios compatibles con OpenAI API

## üîß Configuraci√≥n

1. Haz clic en **‚öôÔ∏è Configurar** en el header
2. Selecciona tu proveedor preferido
3. Configura el endpoint (se detecta autom√°ticamente para servicios locales)
4. Ingresa tu API Key si es necesario
5. Selecciona o ingresa el nombre del modelo
6. Ajusta los par√°metros (temperatura, max tokens, etc.)
7. **Probar Conexi√≥n** para verificar que funciona
8. **Guardar** la configuraci√≥n

## üí° Consejos

- **Para uso local**: Recomendamos LM Studio o Ollama con modelos optimizados para c√≥digo como Qwen2.5-Coder
- **Para uso en producci√≥n**: OpenAI GPT-4 o Claude 3 Sonnet ofrecen excelente calidad
- **Temperatura baja (0.1-0.3)**: Mejor para c√≥digo y respuestas precisas
- **Temperatura alta (0.7-1.0)**: Mejor para creatividad y exploraci√≥n
- **Max Tokens**: 2000-4000 es ideal para la mayor√≠a de casos de uso

## üõ†Ô∏è Soluci√≥n de Problemas

### Error de conexi√≥n local
- Verifica que LM Studio/Ollama est√© ejecut√°ndose
- Comprueba que el puerto est√© correcto (1234 para LM Studio, 11434 para Ollama)
- Verifica que no haya firewall bloqueando las conexiones

### Error de API Key
- Verifica que la API Key sea v√°lida y activa
- Aseg√∫rate de tener cr√©ditos/cuota disponible
- Comprueba que la API Key tenga los permisos correctos

### Error de modelo no encontrado
- Verifica que el modelo est√© disponible en tu proveedor
- Para servicios locales, aseg√∫rate de que el modelo est√© descargado
- Usa "Probar Conexi√≥n" para obtener la lista de modelos disponibles

## üìä Comparaci√≥n de Rendimiento

| Proveedor | Velocidad | Calidad | Costo | Privacidad |
|-----------|-----------|---------|-------|------------|
| LM Studio | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | üü¢ Gratis | üü¢ Local |
| Ollama | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | üü¢ Gratis | üü¢ Local |
| OpenAI | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | üü° Pago | üü° Nube |
| Anthropic | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | üü° Pago | üü° Nube |
